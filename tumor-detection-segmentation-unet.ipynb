{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8184275,"sourceType":"datasetVersion","datasetId":4845959}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T12:44:50.151211Z","iopub.execute_input":"2024-04-21T12:44:50.151656Z","iopub.status.idle":"2024-04-21T12:45:20.336225Z","shell.execute_reply.started":"2024-04-21T12:44:50.151609Z","shell.execute_reply":"2024-04-21T12:45:20.335157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom glob import glob\nimport time\nimport json\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nfrom datetime import datetime \nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import models, layers, regularizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:45:20.337897Z","iopub.execute_input":"2024-04-21T12:45:20.338453Z","iopub.status.idle":"2024-04-21T12:45:36.246516Z","shell.execute_reply.started":"2024-04-21T12:45:20.338422Z","shell.execute_reply":"2024-04-21T12:45:36.245348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (256, 256)\n\ntrain_files = glob.glob('/kaggle/input/kits23-slices/slices/img/*.png')\nmask_files = glob.glob('/kaggle/input/kits23-slices/slices/mask/*.png')\n\nEPOCHS = 80\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:27.684053Z","iopub.execute_input":"2024-04-21T12:46:27.684984Z","iopub.status.idle":"2024-04-21T12:46:28.013383Z","shell.execute_reply.started":"2024-04-21T12:46:27.684941Z","shell.execute_reply":"2024-04-21T12:46:28.012393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def diagnosis(mask):\n    value = np.max(cv2.imread(mask))\n    return '1' if value > 0 else '0'\ndf = pd.DataFrame({\"image_path\": train_files,\n                    \"mask_path\": mask_files,\n                    \"diagnosis\": [diagnosis(x) for x in mask_files]})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:46:31.929023Z","iopub.execute_input":"2024-04-21T12:46:31.930174Z","iopub.status.idle":"2024-04-21T12:49:13.605111Z","shell.execute_reply.started":"2024-04-21T12:46:31.930128Z","shell.execute_reply":"2024-04-21T12:49:13.603881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:17.494565Z","iopub.execute_input":"2024-04-21T12:53:17.495073Z","iopub.status.idle":"2024-04-21T12:53:17.52327Z","shell.execute_reply.started":"2024-04-21T12:53:17.495032Z","shell.execute_reply":"2024-04-21T12:53:17.522002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlabels = ['Training', 'Validation', 'Testing']\nsizes = [2213, 391, 460]\ncolors = ['blue', 'green', 'orange']\nplt.bar(labels, sizes, color=colors)\nplt.title('Dataset 2')\nfor i, v in enumerate(sizes):\n    plt.text(i, v + 30, str(v), ha='center')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:20.81969Z","iopub.execute_input":"2024-04-21T12:53:20.820234Z","iopub.status.idle":"2024-04-21T12:53:21.097457Z","shell.execute_reply.started":"2024-04-21T12:53:20.820164Z","shell.execute_reply":"2024-04-21T12:53:21.096198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"grayscale\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255.\n    mask = mask / 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:37.707025Z","iopub.execute_input":"2024-04-21T12:53:37.708489Z","iopub.status.idle":"2024-04-21T12:53:37.721155Z","shell.execute_reply.started":"2024-04-21T12:53:37.70843Z","shell.execute_reply":"2024-04-21T12:53:37.719936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.1,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')\n\ntrain_gen = train_generator(df_train, BATCH_SIZE, train_generator_args, target_size=IMAGE_SIZE)\n\nval_gen = train_generator(df_val, BATCH_SIZE, dict(), target_size=IMAGE_SIZE)\n\ntest_gen = train_generator(df_test, BATCH_SIZE, dict(), target_size=IMAGE_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:43.033673Z","iopub.execute_input":"2024-04-21T12:53:43.034704Z","iopub.status.idle":"2024-04-21T12:53:43.041057Z","shell.execute_reply.started":"2024-04-21T12:53:43.034665Z","shell.execute_reply":"2024-04-21T12:53:43.040052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smooth=1.\n\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) / (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef iou_loss(y_true, y_pred):\n    return 1 - iou(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:47.933935Z","iopub.execute_input":"2024-04-21T12:53:47.934375Z","iopub.status.idle":"2024-04-21T12:53:47.945768Z","shell.execute_reply.started":"2024-04-21T12:53:47.934343Z","shell.execute_reply":"2024-04-21T12:53:47.944588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block1(inputs, filters):\n    x = Conv2D(filters, (3, 3), padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef encoder_block1(inputs, filters):\n    x = conv_block1(inputs, filters)\n    p = MaxPooling2D(pool_size=(2, 2))(x)\n    return x, p\n\ndef decoder_block1(inputs, filters, concat_layer):\n    x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputs)\n    x = concatenate([x, concat_layer])\n    x = conv_block1(x, filters)\n    return x\n\ndef unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block1(inputs, 32)  # Reduce filters in encoder blocks\n    s2, p2 = encoder_block1(p1, 64)\n    s3, p3 = encoder_block1(p2, 128)\n    s4, p4 = encoder_block1(p3, 256)\n\n    b1 = conv_block1(p4, 512)  # Reduce filters in bottleneck block\n\n    d1 = decoder_block1(b1, 256, s4)  # Reduce filters in decoder blocks\n    d2 = decoder_block1(d1, 128, s3)\n    d3 = decoder_block1(d2, 64, s2)\n    d4 = decoder_block1(d3, 32, s1)\n\n    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(d4)\n\n    unet_model = Model(inputs, outputs, name=\"UNet\")\n    return unet_model\n\nunet_model = unet((256, 256, 1))\nunet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:54.925071Z","iopub.execute_input":"2024-04-21T12:53:54.925515Z","iopub.status.idle":"2024-04-21T12:53:55.609784Z","shell.execute_reply.started":"2024-04-21T12:53:54.925481Z","shell.execute_reply":"2024-04-21T12:53:55.607992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-7, amsgrad=False)\nunet_model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[\"accuracy\", iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet.hdf5.keras', verbose=0, save_best_only=True),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n             EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n\nimport math  # Import math module for rounding functions\n\n# Calculate the number of steps per epoch\nsteps_per_epoch = math.ceil(len(df_train) / BATCH_SIZE)\n\n# Similarly, calculate the number of validation steps\nvalidation_steps = math.ceil(len(df_val) / BATCH_SIZE)\n\n# Use the calculated steps_per_epoch and validation_steps in the fit method\nhistory_unet = unet_model.fit(\n    train_gen,\n    steps_per_epoch=steps_per_epoch,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    validation_data=val_gen,\n    validation_steps=validation_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:56:21.969851Z","iopub.execute_input":"2024-04-21T12:56:21.97031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('unet.hdf5.keras', custom_objects={'bce_dice_loss': bce_dice_loss, 'accuracy': \"accuracy\", 'iou': iou, 'dice_coef': dice_coef})\nresults = unet_model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\nprint(\"Loss:\", results[0])\nprint(\"Accuracy:\", results[1])\nprint(\"IoU Score:\", results[2])\nprint(\"Dice Score:\", results[3])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = history_unet.history\npd.DataFrame.from_dict(history_dict).to_csv('history_unet.csv', index = False)\nhistory_unet_df = pd.read_csv('history_unet.csv')\n\n# Set the height of each subplot\nfig, axs = plt.subplots(nrows=4, ncols=1, figsize=(8, 20))\n\n# Adjust the space between subplots\nplt.subplots_adjust(hspace=0.5)\n\n# Plot the loss\naxs[0].plot(history_unet_df['loss'], 'b-', label='Training Loss')\naxs[0].plot(history_unet_df['val_loss'], 'r-', label='Validation Loss')\naxs[0].set_xlabel('Epochs')\naxs[0].set_ylabel('Loss')\naxs[0].legend(loc='best')\n\n# Plot the accuracy\naxs[1].plot(history_unet_df['accuracy'], 'b-', label='Training Accuracy')\naxs[1].plot(history_unet_df['val_accuracy'], 'r-', label='Validation Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Accuracy')\naxs[1].legend(loc='best')\n\n# Plot the IOU\naxs[2].plot(history_unet_df['iou'], 'b-', label='Training IOU')\naxs[2].plot(history_unet_df['val_iou'], 'r-', label='Validation IOU')\naxs[2].set_xlabel('Epochs')\naxs[2].set_ylabel('IOU')\naxs[2].legend(loc='best')\n\n# Plot the dice coefficient\naxs[3].plot(history_unet_df['dice_coef'], 'b-', label='Training Dice Coefficient')\naxs[3].plot(history_unet_df['val_dice_coef'], 'r-', label='Validation Dice Coefficient')\naxs[3].set_xlabel('Epochs')\naxs[3].set_ylabel('Dice Coefficient')\naxs[3].legend(loc='best')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):  \n    # Select a random image from the test set\n    index = np.random.randint(1, len(df_test.index))\n\n    # Load the image and preprocess it\n    img = cv2.imread(df_test['image_path'].iloc[index], cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, IMAGE_SIZE)\n    img = img / 255\n    img = img[:, :, np.newaxis]\n    img = np.expand_dims(img, axis=0)\n\n    # Measure the inference time for UNet\n    start_time = time.time()\n    pred_unet = unet_model.predict(img)\n    end_time = time.time()\n    unet_inference_time = (end_time - start_time) * 1000\n\n    # Plot the original image and masks, as well as the predictions\n    plt.figure(figsize=(8, 4))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img), cmap='gray') \n    plt.title('Image')\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])), cmap='gray')  \n    plt.title('Ground Truth')\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(pred_unet) > .5, cmap='gray')  \n    plt.title('UNet Prediction')\n    plt.show()\n    \n    # Print the inference time for UNet\n    print(f'UNet Inference Time: {unet_inference_time:.4f} ms')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/unet.hdf5'\nmodel = load_model(model_path, compile=False)\n\ndef highlight_tumor(image_path, model):\n    # Read the image\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 256))\n    image = image / 255.0  # Normalize the image\n\n    # Expand dimensions to match model input shape\n    image = np.expand_dims(image, axis=(0, -1))\n\n    # Perform segmentation\n    mask = model.predict(image)\n\n    # Threshold the mask\n    threshold = 0.5\n    mask_binary = (mask > threshold).astype(np.uint8)\n\n    # Convert the original image to RGB (for visualization purposes)\n    original_image_rgb = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n    # Resize the mask to match the size of the original image\n    highlight_mask_resized = cv2.resize(mask_binary[0], (original_image_rgb.shape[1], original_image_rgb.shape[0]))\n\n    # Create a mask to highlight the tumor region in red\n    highlight_mask = cv2.cvtColor(highlight_mask_resized, cv2.COLOR_GRAY2RGB)\n    highlight_mask[:, :, 0] = np.where(highlight_mask[:, :, 0] > 0, 255, 0)  # Set red channel to 255 where tumor is present\n    highlight_mask[:, :, 1] = 0  # Set green channel to 0\n    highlight_mask[:, :, 2] = 0  # Set blue channel to 0\n\n    # Combine the original image with the highlight mask\n    highlighted_image = cv2.addWeighted(original_image_rgb, 0.7, highlight_mask, 0.3, 0)\n\n    # Display the highlighted image\n    plt.imshow(highlighted_image)\n    plt.title('Highlighted Tumor')\n    plt.axis('off')\n    plt.show()\n\n# Example usage:\nimage_path = '/kaggle/input/brain-tumor-segmentation/images/1.png'  # Update with the path to your image file\nhighlight_tumor(image_path, model)","metadata":{},"execution_count":null,"outputs":[]}]}